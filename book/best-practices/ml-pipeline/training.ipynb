{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 및 평가\n",
    "\n",
    "## 개요\n",
    "DataFabric의 JupyterHub 환경에서 머신러닝 모델을 만들고 평가할 수 있습니다.\n",
    "DataFabric 분석환경은 Scikit-Learn과 LightGBM 같은 머신러닝 파이썬 패키지를 제공하며 노트북에서 이를 임포트하여 사용할 수 있습니다.\n",
    "이 문서에서는 구글 빅쿼리에 저장된 데이터를 활용하여 추천 모델을 학습하고 평가하는 예제를 설명합니다.\n",
    "\n",
    "\n",
    "## 모델 학습\n",
    "모델 학습 주제 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 확인\n",
    "\n",
    "학습 데이터셋을 만들기 전에 먼저 활용할 데이터를 확인해보는 과정입니다.  \n",
    "사용자 Feature 정보와 라벨링 데이터를 저장하고 있는 테이블을 다음과 같이 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:58:56.217523Z",
     "iopub.status.busy": "2022-10-06T07:58:56.217066Z",
     "iopub.status.idle": "2022-10-06T07:58:56.822535Z",
     "shell.execute_reply": "2022-10-06T07:58:56.821968Z",
     "shell.execute_reply.started": "2022-10-06T07:58:56.217446Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydatafabric.gcp import load_bigquery_ipython_magic\n",
    "\n",
    "load_bigquery_ipython_magic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:58:59.095927Z",
     "iopub.status.busy": "2022-10-06T07:58:59.095414Z",
     "iopub.status.idle": "2022-10-06T07:59:00.843578Z",
     "shell.execute_reply": "2022-10-06T07:59:00.843023Z",
     "shell.execute_reply.started": "2022-10-06T07:58:59.095892Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 848.88query/s]                          \n",
      "Downloading: 100%|██████████| 10/10 [00:00<00:00, 10.85rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery execution took 1 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YM_WCNT</th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>AFLCO_CD</th>\n",
       "      <th>DATA_CRTN_DT</th>\n",
       "      <th>TOP1_STR_CD</th>\n",
       "      <th>TOP1_STR_LA</th>\n",
       "      <th>TOP1_STR_LO</th>\n",
       "      <th>TOP1_STR_DSTNC</th>\n",
       "      <th>TOP2_STR_CD</th>\n",
       "      <th>TOP2_STR_LA</th>\n",
       "      <th>...</th>\n",
       "      <th>DAVG_PURCHS_AMT_CHG_RT</th>\n",
       "      <th>TPO1</th>\n",
       "      <th>TPO2</th>\n",
       "      <th>TPO3</th>\n",
       "      <th>TPO4</th>\n",
       "      <th>TPO5</th>\n",
       "      <th>TPO6</th>\n",
       "      <th>TPO7</th>\n",
       "      <th>TPO8</th>\n",
       "      <th>TOP1_TPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20171201</td>\n",
       "      <td>8056f402b3d963f0cbcff845ea64b280a00ef445d275fd...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20171201</td>\n",
       "      <td>39808435f1c26cd29d59b7a9243d42781377a5c1fcbed3...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20171201</td>\n",
       "      <td>c9a6519cb7f228615631025e3b5752e779c5957236c7b9...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20171201</td>\n",
       "      <td>8620552c06ba3c2b0835bf6779a2d4a684711ed60a3cdd...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20171201</td>\n",
       "      <td>9c18c04289d62bee80b6f65ed3ff6466f2d787aec29523...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20171201</td>\n",
       "      <td>2967aa273b1bcc4a0d73cf944c3fe4dd56a70d6981bab3...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20171201</td>\n",
       "      <td>74c4fbb2a1c23ba9519215fc0123c283eeddd3129ce79c...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20171201</td>\n",
       "      <td>7042067d5f3a3a0e17fa39432f1df39b0e60dc79cd5574...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20171201</td>\n",
       "      <td>7dd5d5765ac38a26aeac087eefaac4b98033cf28e64949...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20171201</td>\n",
       "      <td>2af3c4c56fd201efe456757dbef25e4e3e751b18717d4a...</td>\n",
       "      <td>001</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.063142000</td>\n",
       "      <td>0.042987000</td>\n",
       "      <td>0.057184000</td>\n",
       "      <td>0.636070000</td>\n",
       "      <td>0.033535000</td>\n",
       "      <td>0.024865000</td>\n",
       "      <td>0.114329000</td>\n",
       "      <td>0.027889000</td>\n",
       "      <td>TPO4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    YM_WCNT                                            CUST_ID AFLCO_CD  \\\n",
       "0  20171201  8056f402b3d963f0cbcff845ea64b280a00ef445d275fd...      001   \n",
       "1  20171201  39808435f1c26cd29d59b7a9243d42781377a5c1fcbed3...      001   \n",
       "2  20171201  c9a6519cb7f228615631025e3b5752e779c5957236c7b9...      001   \n",
       "3  20171201  8620552c06ba3c2b0835bf6779a2d4a684711ed60a3cdd...      001   \n",
       "4  20171201  9c18c04289d62bee80b6f65ed3ff6466f2d787aec29523...      001   \n",
       "5  20171201  2967aa273b1bcc4a0d73cf944c3fe4dd56a70d6981bab3...      001   \n",
       "6  20171201  74c4fbb2a1c23ba9519215fc0123c283eeddd3129ce79c...      001   \n",
       "7  20171201  7042067d5f3a3a0e17fa39432f1df39b0e60dc79cd5574...      001   \n",
       "8  20171201  7dd5d5765ac38a26aeac087eefaac4b98033cf28e64949...      001   \n",
       "9  20171201  2af3c4c56fd201efe456757dbef25e4e3e751b18717d4a...      001   \n",
       "\n",
       "  DATA_CRTN_DT TOP1_STR_CD TOP1_STR_LA TOP1_STR_LO TOP1_STR_DSTNC TOP2_STR_CD  \\\n",
       "0   2020-02-22        None        None        None           None        None   \n",
       "1   2020-02-22        None        None        None           None        None   \n",
       "2   2020-02-22        None        None        None           None        None   \n",
       "3   2020-02-22        None        None        None           None        None   \n",
       "4   2020-02-22        None        None        None           None        None   \n",
       "5   2020-02-22        None        None        None           None        None   \n",
       "6   2020-02-22        None        None        None           None        None   \n",
       "7   2020-02-22        None        None        None           None        None   \n",
       "8   2020-02-22        None        None        None           None        None   \n",
       "9   2020-02-22        None        None        None           None        None   \n",
       "\n",
       "  TOP2_STR_LA  ... DAVG_PURCHS_AMT_CHG_RT         TPO1         TPO2  \\\n",
       "0        None  ...                   None  0.063142000  0.042987000   \n",
       "1        None  ...                   None  0.063142000  0.042987000   \n",
       "2        None  ...                   None  0.063142000  0.042987000   \n",
       "3        None  ...                   None  0.063142000  0.042987000   \n",
       "4        None  ...                   None  0.063142000  0.042987000   \n",
       "5        None  ...                   None  0.063142000  0.042987000   \n",
       "6        None  ...                   None  0.063142000  0.042987000   \n",
       "7        None  ...                   None  0.063142000  0.042987000   \n",
       "8        None  ...                   None  0.063142000  0.042987000   \n",
       "9        None  ...                   None  0.063142000  0.042987000   \n",
       "\n",
       "          TPO3         TPO4         TPO5         TPO6         TPO7  \\\n",
       "0  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "1  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "2  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "3  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "4  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "5  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "6  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "7  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "8  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "9  0.057184000  0.636070000  0.033535000  0.024865000  0.114329000   \n",
       "\n",
       "          TPO8 TOP1_TPO  \n",
       "0  0.027889000     TPO4  \n",
       "1  0.027889000     TPO4  \n",
       "2  0.027889000     TPO4  \n",
       "3  0.027889000     TPO4  \n",
       "4  0.027889000     TPO4  \n",
       "5  0.027889000     TPO4  \n",
       "6  0.027889000     TPO4  \n",
       "7  0.027889000     TPO4  \n",
       "8  0.027889000     TPO4  \n",
       "9  0.027889000     TPO4  \n",
       "\n",
       "[10 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bq \n",
    "SELECT * \n",
    "FROM  smart-ruler-304409.test_cds_dataset.TB_AMT_AFLCO_CUST_DNA_DATA \n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습 데이터 생성\n",
    "구글 빅쿼리에 저장된 데이터를 다음과 같이 쿼리하여 Pandas DataFrame으로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:59:12.977076Z",
     "iopub.status.busy": "2022-10-06T07:59:12.976695Z",
     "iopub.status.idle": "2022-10-06T07:59:14.323001Z",
     "shell.execute_reply": "2022-10-06T07:59:14.322425Z",
     "shell.execute_reply.started": "2022-10-06T07:59:12.977051Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destination: emart-datafabric._2dd36219768c7c869a5680edf9fd6e104ea57800.anon92f91edc96845647322ad4a65c196f3ba122b3b9cc29eb81114f305ffc3bf804\n",
      "total_rows: 0\n",
      "slot_secs: 0.042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 0rows [00:00, ?rows/s]\n"
     ]
    }
   ],
   "source": [
    "from pydatafabric.gcp import bq_to_pandas\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT * \n",
    "FROM  smart-ruler-304409.test_cds_dataset.TB_AMT_AFLCO_CUST_DNA_DATA \n",
    "WHERE YM_WCNT='20220301'\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "df = bq_to_pandas(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값을 포함하는 데이터를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:59:18.044309Z",
     "iopub.status.busy": "2022-10-06T07:59:18.043900Z",
     "iopub.status.idle": "2022-10-06T07:59:18.048750Z",
     "shell.execute_reply": "2022-10-06T07:59:18.048179Z",
     "shell.execute_reply.started": "2022-10-06T07:59:18.044282Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:59:18.205513Z",
     "iopub.status.busy": "2022-10-06T07:59:18.205119Z",
     "iopub.status.idle": "2022-10-06T07:59:18.215990Z",
     "shell.execute_reply": "2022-10-06T07:59:18.215485Z",
     "shell.execute_reply.started": "2022-10-06T07:59:18.205485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YM_WCNT</th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>AFLCO_CD</th>\n",
       "      <th>DATA_CRTN_DT</th>\n",
       "      <th>TOP1_STR_CD</th>\n",
       "      <th>TOP1_STR_LA</th>\n",
       "      <th>TOP1_STR_LO</th>\n",
       "      <th>TOP1_STR_DSTNC</th>\n",
       "      <th>TOP2_STR_CD</th>\n",
       "      <th>TOP2_STR_LA</th>\n",
       "      <th>...</th>\n",
       "      <th>TPO1</th>\n",
       "      <th>TPO2</th>\n",
       "      <th>TPO3</th>\n",
       "      <th>TPO4</th>\n",
       "      <th>TPO5</th>\n",
       "      <th>TPO6</th>\n",
       "      <th>TPO7</th>\n",
       "      <th>TPO8</th>\n",
       "      <th>TOP1_TPO</th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [YM_WCNT, CUST_ID, AFLCO_CD, DATA_CRTN_DT, TOP1_STR_CD, TOP1_STR_LA, TOP1_STR_LO, TOP1_STR_DSTNC, TOP2_STR_CD, TOP2_STR_LA, TOP2_STR_LO, TOP2_STR_DSTNC, WETHR_SNTV_UNITY, WETHR_SNTV_COLD, WETHR_SNTV_HOT, WETHR_SNTV_RAIN, WETHR_SNTV_SNOW, WETHR_SNTV_FNDS, CLDR_EVENT_PRE_UNITY, CLDR_EVENT_PRE_TREDI, CLDR_EVENT_PRE_XMAS, CLDR_EVENT_PRE_MAY, CLDR_EVENT_PRE_SCHUL, PURCHS_TM_WKD_01_03, PURCHS_TM_WKD_04_06, PURCHS_TM_WKD_07_09, PURCHS_TM_WKD_10_12, PURCHS_TM_WKD_13_15, PURCHS_TM_WKD_16_18, PURCHS_TM_WKD_19_21, PURCHS_TM_WKD_22_24, PURCHS_TM_WEND_HLDY_01_03, PURCHS_TM_WEND_HLDY_04_06, PURCHS_TM_WEND_HLDY_07_09, PURCHS_TM_WEND_HLDY_10_12, PURCHS_TM_WEND_HLDY_13_15, PURCHS_TM_WEND_HLDY_16_18, PURCHS_TM_WEND_HLDY_19_21, PURCHS_TM_WEND_HLDY_22_24, PURCHS_WKD, PURCHS_WEND_HLDY, PURCHS_CYCLE, PURCHS_CYCLE_CHG, PURCHS_CYCLE_REGUL_YN, PURCHS_CYCLE_CHG_RT, PURCHS_CYCLE_ARRVL_RT, PURCHS_CYCLE_ELAPSE, HGHPC_PREFER, PURCHS_DCODE_NUM_AVG, PURCHS_DCODE_NUM_CHG, PURCHS_DCODE_NUM_CHG_RT, DAVG_PURCHS_AMT_SFRUIT, DAVG_PURCHS_AMT_CFRUIT, DAVG_PURCHS_AMT_MEAT, DAVG_PURCHS_AMT_HEALTH, DAVG_PURCHS_AMT_CFRESH, DAVG_PURCHS_AMT_HMR, DAVG_PURCHS_AMT_LIQUOR, DAVG_PURCHS_AMT_REFRIG, DAVG_PURCHS_AMT_KITCHEN, DAVG_PURCHS_AMT_SOCKS, DAVG_PURCHS_AMT_UNDERW, DAVG_PURCHS_AMT_SPROTS, MAIN_PURCHS_DCODE, PREFER_PURCHS_DCODE, CUST_GRADE_CD, DAVG_PURCHS_AMT, DAVG_PURCHS_AMT_EXC_ELEC, DAVG_PURCHS_AMT_CHG, DAVG_PURCHS_AMT_CHG_RT, TPO1, TPO2, TPO3, TPO4, TPO5, TPO6, TPO7, TPO8, TOP1_TPO, column]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df[\"column\"] = np.random.randint(0.0,1.0, size=len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨 정보를 숫자로 인코딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T07:59:41.212937Z",
     "iopub.status.busy": "2022-10-06T07:59:41.212526Z",
     "iopub.status.idle": "2022-10-06T07:59:41.216674Z",
     "shell.execute_reply": "2022-10-06T07:59:41.216114Z",
     "shell.execute_reply.started": "2022-10-06T07:59:41.212911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoding'] = le.fit_transform(df['column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 Feature를 x로 라벨을 y로 하는 데이터셋을 만듭니다.  \n",
    "데이터셋은 학습과 평가로 나누도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-06T08:00:27.626696Z",
     "iopub.status.busy": "2022-10-06T08:00:27.626210Z",
     "iopub.status.idle": "2022-10-06T08:00:27.658473Z",
     "shell.execute_reply": "2022-10-06T08:00:27.657490Z",
     "shell.execute_reply.started": "2022-10-06T08:00:27.626668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cols \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(idx_col))\n\u001b[1;32m      7\u001b[0m label_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_encoding\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m train_x, valid_x, train_y, valid_y \u001b[38;5;241m=\u001b[39m train_test_split(df[features], df[label_col], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2420\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2417\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2419\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2420\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2098\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2095\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2098\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2102\u001b[0m     )\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx_col = ['CUST_ID', 'dt', 'column', 'dataset_type', 'label', 'label_dt', 'label_encoding']\n",
    "cols = set(df.columns)\n",
    "features = list(cols - set(idx_col))\n",
    "\n",
    "label_col = 'label_encoding'\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df[features], df[label_col], test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 좋은 변수만 사용하도록 처리하여 데이터셋을 생성하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "first_k = SelectKBest(score_func=f_classif).fit(train_x, train_y)\n",
    "score = first_k.scores_\n",
    "importance_df = pd.DataFrame(index=train_x.columns, data={'score':first_k.scores_}).sort_values('score', ascending=False)\n",
    "\n",
    "k = 100\n",
    "k_features = list(importance_df.index[:k])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "lgb_trn = lgb.Dataset(train_x[k_features], train_y, feature_name=k_features)\n",
    "lgb_val = lgb.Dataset(valid_x[k_features], valid_y, feature_name=k_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 학습\n",
    "\n",
    "준비된 데이터셋을 이용하여 학습을 합니다. 우선 Bayesian Optimazation을 이용해서 하이퍼 파라미터를 최적화하는 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "LR = 0.05\n",
    "NUM_THREAD = 8\n",
    "\n",
    "def lgb_eval(num_leaves, feature_fraction, lambda_l1, lambda_l2, num_boost_round):\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclassova',\n",
    "        'num_class': num_classes,\n",
    "        'metric': 'multi_logloss',\n",
    "        'is_unbalance': True,\n",
    "        'learning_rate': LR,\n",
    "        'num_threads': NUM_THREAD,\n",
    "        'num_leaves': int(num_leaves),\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'lambda_l1': lambda_l1,\n",
    "        'lambda_l2': lambda_l2\n",
    "    }\n",
    "    \n",
    "    num_boost_round = int(num_boost_round)\n",
    "    \n",
    "    print('num_leaves: ', num_leaves)\n",
    "    print('feature_fraction: ', feature_fraction)\n",
    "    print('lambda_l1: ', lambda_l1)\n",
    "    print('lambda_l2: ', lambda_l2)\n",
    "    print('_num_boost_round: ', num_boost_round)\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    train_set=lgb_trn,\n",
    "                    valid_sets=lgb_val,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=False)\n",
    "    \n",
    "    return clf.best_score['valid_0']['multi_logloss']\n",
    "\n",
    "TARGET_PARAMS = {'num_leaves': (8, 64),\n",
    "                 'feature_fraction': (0.5, 1.0),\n",
    "                 'lambda_l1': (0, 100),\n",
    "                 'lambda_l2': (0, 1000),\n",
    "                 'num_boost_round': (500, 2000)}\n",
    "\n",
    "lgbBO = BayesianOptimization(lgb_eval, TARGET_PARAMS)\n",
    "lgbBO.maximize(init_points=5, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.DataFrame(lgbBO.res)['target'], pd.json_normalize(pd.DataFrame(lgbBO.res)['params'])], axis=1).sort_values(by='target')[::1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화된 파라미터를 사용하여 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclassova',\n",
    "    'num_class': len(le.classes_),\n",
    "    'metric': 'multi_logloss',\n",
    "    'is_unbalance': True,\n",
    "    'num_threads': NUM_THREAD,\n",
    "    'num_leaves': result['num_leaves'].iloc[0].astype('int32'),\n",
    "    'feature_fraction': result['feature_fraction'].iloc[0],\n",
    "    'learning_rate': LR,\n",
    "    'lambda_l1': result['lambda_l1'].iloc[0],\n",
    "    'lambda_l2': result['lambda_l2'].iloc[0]\n",
    "}\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df[k_features], df[label_col], test_size=0.2, random_state=1234)\n",
    "lgb_trn = lgb.Dataset(train_x, train_y)\n",
    "lgb_val = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "# training\n",
    "clf = lgb.train(lgb_params,\n",
    "                train_set=lgb_trn,\n",
    "                valid_sets=[lgb_trn, lgb_val],\n",
    "                num_boost_round=5000,\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 학습된 모델 평가\n",
    "\n",
    "학습한 모델을 평가하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# model evaluation\n",
    "def model_evaluation(model, x_trn, y_trn, top_k):\n",
    "    # cross-table\n",
    "    predict = model.predict(x_trn).argmax(axis=1)\n",
    "    print(pd.crosstab(predict, y_trn))\n",
    "    \n",
    "    # metric by each label\n",
    "    labels, cnt = np.unique(predict, return_counts=True)\n",
    "    metrics_summary = precision_recall_fscore_support(y_true=y_trn, y_pred=predict, labels=labels)\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    \n",
    "    class_report = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index = metrics_sum_index,\n",
    "        columns = labels)\n",
    "    \n",
    "    print(class_report.T)\n",
    "    \n",
    "    # metric by each label\n",
    "    y_tmp = pd.DataFrame(y_trn).reset_index(drop=True)\n",
    "    y_tmp['pred_score'] = list(map(lambda x: x.argsort()[-top_k:][::-1], model.predict(x_trn)))\n",
    "    y_tmp['flag'] = y_tmp.apply(lambda x: int(x['label_encoding'] in x['pred_score']), axis=1)\n",
    "    acc = y_tmp['flag'].sum()/y_tmp['flag'].count()\n",
    "    print(acc)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print(\"[Accuracy for Training Set]\")\n",
    "acc_trn = model_evaluation(clf, train_x, train_y, 3)\n",
    "\n",
    "print(\"[Accuracy for Validation Set]\")\n",
    "acc_val = model_evaluation(clf, valid_x, valid_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 모델은 이후 Prediction 단계에서 사용될 수 있습니다.  \n",
    "다음 단계에서 사용하기 위해 HDFS에 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pydatafabric.ye import get_hdfs_conn\n",
    "\n",
    "model_name = 'example_model'\n",
    "model_version = 'v0'\n",
    "\n",
    "clf.params['label_encoder'] = le\n",
    "clf.params['training_multi_logloss'] = clf.best_score['training']['multi_logloss']\n",
    "clf.params['valid_multi_logloss'] = clf.best_score['valid_1']['multi_logloss']\n",
    "clf.params['acc_trn'] = acc_trn\n",
    "clf.params['acc_val'] = acc_val\n",
    "clf.params['model_name'] = model_name\n",
    "clf.params['model_version'] = model_version\n",
    "\n",
    "# save model file\n",
    "output_path = f'/data/tmp/{model_name}/{model_version}'\n",
    "connection = get_hdfs_conn()\n",
    "with connection.open(os.path.join(output_path), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고로 mlops-sdk를 사용하여 모델의 형상을 관리하실 수 있습니다.\n",
    "모델 관리를 위해서는 mlops에 모델을 등록하셔야 됩니다. MLS에 대한 자세한 내용은 <a href=\"https://rec.shinsegae.ai/swagger/index.html\" target=\"_blank\">mlops-sdk 문서</a>를 참고하시기 바랍니다.\n",
    "아래는 실제 등록된 모델이 저장된 경로를 가져오는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Code Example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

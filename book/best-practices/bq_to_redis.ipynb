{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c155c-2d99-4bc6-9427-3287f56fc9ac",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dt='20211217'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53e562-f977-4783-b1cd-63bdd8e233ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "c_dt = datetime.strptime(dt, '%Y%m%d')\n",
    "\n",
    "c_dt = c_dt + timedelta(days=-1)\n",
    "o_dt = c_dt + timedelta(days=-1)\n",
    "\n",
    "c_dt = datetime.strftime(c_dt, '%Y%m%d')\n",
    "o_dt = datetime.strftime(o_dt, '%Y%m%d')\n",
    "\n",
    "print('c_dt : %s' % c_dt)\n",
    "print('o_dt : %s' % o_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd45ed-f648-4010-bbec-acc840039717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hvac\n",
    "import urllib3\n",
    "\n",
    "def get_secrets(path):\n",
    "    # Warning 제거\n",
    "    urllib3.disable_warnings()\n",
    "\n",
    "    secrets = hvac.Client(verify=False).secrets.kv.v2.read_secret_version(path=path)[\"data\"][\"data\"]\n",
    "    return secrets\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "redis_info = get_secrets(path=\"unhash-redis-cluster\")\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.set(\"spark.jars\", \"hdfs:///jars/spark-redis_2.11-2.5.0-SNAPSHOT-jar-with-dependencies.jar\")\n",
    "\n",
    "sparkConf.set(\"spark.redis.host\", redis_info['host'])\n",
    "sparkConf.set(\"spark.redis.port\", redis_info['port'])\n",
    "sparkConf.set(\"spark.redis.auth\", redis_info['password'])\n",
    "sparkConf.set('spark.sql.execution.arrow.pyspark.enabled', 'true')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c3d22-3a76-4d13-b6ca-d95fb1f85f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\" select ye_hashed, raw from aidp.svc_mgmt_num_mapping where dt={c_dt} \"\"\").registerTempTable('latest_table')\n",
    "spark.sql(f\"\"\" select ye_hashed, raw from aidp.svc_mgmt_num_mapping where dt={o_dt} \"\"\").registerTempTable('old_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfce5c5-089e-473d-9375-eea8d97f0cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "\n",
    "    select\n",
    "        l.ye_hashed,\n",
    "        l.raw\n",
    "    from \n",
    "        latest_table l left outer join old_table o\n",
    "        on l.raw = o.raw\n",
    "    where\n",
    "        o.raw is null\n",
    "        and l.ye_hashed is not null\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bece4a1-6425-4e3c-a28e-acbfb51ace59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if df.count() > 0:\n",
    "    df.write.format(\"org.apache.spark.sql.redis\").option(\"table\", \"unhash\").option(\"key.column\", \"ye_hashed\").save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc5439-8f16-4be0-b910-7ba09367e1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

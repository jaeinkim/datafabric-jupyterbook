{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydatafabric.gcp import bq_to_pandas\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql+psycopg2://aim:!aim00@172.27.124.13/aim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery 일별 사용량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = bq_to_pandas(\"\"\"\n",
    "  WITH data as\n",
    "  (\n",
    "    SELECT\n",
    "      protopayload_auditlog.authenticationInfo.principalEmail as principalEmail,\n",
    "      protopayload_auditlog.metadataJson AS metadataJson,\n",
    "      CAST(JSON_EXTRACT_SCALAR(protopayload_auditlog.metadataJson,\n",
    "          \"$.jobChange.job.jobStats.queryStats.totalBilledBytes\") AS INT64) AS totalBilledBytes,\n",
    "      CAST(TIMESTAMP_ADD(timestamp, INTERVAL 9 HOUR) AS DATE) AS baseDate\n",
    "    FROM\n",
    "      `emart-datafabric.audit_v2.cloudaudit_googleapis_com_data_access`\n",
    "  )\n",
    "  SELECT format_date('%Y-%m-%d', baseDate) as dt, count(baseDate) as query_count, FORMAT('%9.2f',SUM(totalBilledBytes)/POWER(2, 30)) total_billed_giga_bytes\n",
    "  FROM\n",
    "    data\n",
    "  WHERE\n",
    "    JSON_EXTRACT_SCALAR(metadataJson, \"$.jobChange.job.jobConfig.type\") = \"QUERY\"\n",
    "    AND principalEmail LIKE '%@shinsegae.ai'\n",
    "    GROUP BY baseDate\n",
    "    ORDER BY baseDate \n",
    "\"\"\")\n",
    "\n",
    "df.to_sql('temp_bigquery_stats_daily_usage', engine, if_exists='replace', index=False)\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO bigquery_stats_daily_usage\n",
    "        SELECT date(dt) as dt, cast(query_count as int), cast(total_billed_giga_bytes as float)\n",
    "        FROM temp_bigquery_stats_daily_usage\n",
    "        ON CONFLICT (dt) \n",
    "        DO \n",
    "           UPDATE SET query_count = excluded.query_count, total_billed_giga_bytes = excluded.total_billed_giga_bytes\n",
    "        \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery 최근 1주일 사용자별 사용량 및 쿼리수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = bq_to_pandas(\"\"\"\n",
    "WITH data as\n",
    "  (\n",
    "    SELECT\n",
    "      protopayload_auditlog.authenticationInfo.principalEmail as principalEmail,\n",
    "      protopayload_auditlog.metadataJson AS metadataJson,\n",
    "      CAST(JSON_EXTRACT_SCALAR(protopayload_auditlog.metadataJson,\n",
    "          \"$.jobChange.job.jobStats.queryStats.totalBilledBytes\") AS INT64) AS totalBilledBytes,\n",
    "      CAST(TIMESTAMP_ADD(timestamp, INTERVAL 9 HOUR) AS DATE) AS baseDate\n",
    "    FROM\n",
    "      `emart-datafabric.audit_v2.cloudaudit_googleapis_com_data_access`\n",
    "    WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)\n",
    "  )\n",
    "  SELECT\n",
    "    split(principalEmail, '@')[offset(0)] as user_id,\n",
    "    count(principalEmail) as query_count,\n",
    "    FORMAT('%9.2f',SUM(totalBilledBytes)/POWER(2, 40)) AS total_billed_giga_bytes\n",
    "  FROM\n",
    "    data\n",
    "  WHERE\n",
    "    JSON_EXTRACT_SCALAR(metadataJson, \"$.jobChange.job.jobConfig.type\") = \"QUERY\"\n",
    "    AND principalEmail LIKE '%@shinsegae.ai' AND principalEmail LIKE 'x%'\n",
    "  GROUP BY principalEmail\n",
    "  ORDER BY query_count DESC\n",
    "\"\"\")\n",
    "\n",
    "df.to_sql('temp_bigquery_stats_user_usage', engine, if_exists='replace', index=False)\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO bigquery_stats_user_usage (user_id, query_count, total_billed_giga_bytes)\n",
    "        SELECT user_id, query_count, cast(total_billed_giga_bytes as float)\n",
    "        FROM temp_bigquery_stats_user_usage\n",
    "        ON CONFLICT (user_id) \n",
    "        DO \n",
    "           UPDATE SET query_count = excluded.query_count, total_billed_giga_bytes = excluded.total_billed_giga_bytes\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery 오늘 전체 용량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = bq_to_pandas(\"\"\"\n",
    "    select format_timestamp('%Y-%m-%d', current_timestamp(), 'Asia/Seoul') as dt, sum(round(IEEE_DIVIDE(size_bytes, 1024*1024*1024))) as total_volume\n",
    "    from `x1112275.all_tables*`\n",
    "    where _table_suffix = (SELECT MAX(_TABLE_SUFFIX) FROM `x1112275.all_tables*`)\n",
    "    and size_bytes > 100*1024*1024*1024\n",
    "\"\"\")\n",
    "\n",
    "df.to_sql('temp_bigquery_stats_dataset_volume', engine, if_exists='replace', index=False)\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO bigquery_stats_dataset_volume (dt, total_volume)\n",
    "        SELECT date(dt), total_volume\n",
    "        FROM temp_bigquery_stats_dataset_volume\n",
    "        ON CONFLICT (dt) \n",
    "        DO \n",
    "           UPDATE SET total_volume = excluded.total_volume\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery 데이터세트 별 용량 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = bq_to_pandas(\"\"\"\n",
    "    with total as (\n",
    "        select sum(round(IEEE_DIVIDE(size_bytes, 1024*1024*1024))) as value\n",
    "        from `x1112275.all_tables*`\n",
    "        where _table_suffix = (SELECT MAX(_TABLE_SUFFIX) FROM `x1112275.all_tables*`)\n",
    "        and size_bytes > 100*1024*1024*1024\n",
    "        and project_id = 'emart-datafabric'\n",
    "    )\n",
    "    select dataset_id,\n",
    "        sum(round(IEEE_DIVIDE(size_bytes, 1024*1024*1024))) / (select value from total) as ratio\n",
    "    from `x1112275.all_tables*`\n",
    "    where _table_suffix = (SELECT MAX(_TABLE_SUFFIX) FROM `x1112275.all_tables*`)\n",
    "    and size_bytes > 100*1024*1024*1024\n",
    "    and project_id = 'emart-datafabric'\n",
    "    group by dataset_id\n",
    "    order by ratio desc\n",
    "    limit 5\n",
    "\"\"\")\n",
    "\n",
    "df.to_sql('temp_bigquery_stats_dataset_volume_ratio', engine, if_exists='replace', index=False)\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO bigquery_stats_dataset_volume_ratio (dataset_id, ratio)\n",
    "        SELECT dataset_id, ratio\n",
    "        FROM temp_bigquery_stats_dataset_volume_ratio\n",
    "        ON CONFLICT (dataset_id) \n",
    "        DO \n",
    "           UPDATE SET ratio = excluded.ratio\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCP 이번달 비용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = bq_to_pandas(\"\"\"\n",
    "    SELECT\n",
    "      format_timestamp ('%Y-%m', current_timestamp, 'Asia/Seoul') AS ym,\n",
    "      ROUND(SUM(cost)) AS cost\n",
    "    FROM\n",
    "      `billing_edp.gcp_billing_export_v1_01070F_9BDCB3_2A6D6F`\n",
    "    WHERE\n",
    "      format_timestamp ('%Y/%m',\n",
    "        current_timestamp,\n",
    "        'Asia/Seoul') = format_timestamp ('%Y/%m',\n",
    "        usage_start_time,\n",
    "        'Asia/Seoul')\n",
    "      AND cost >= 1\n",
    "      AND project.name IN ('emart-datafabric')\n",
    "\"\"\")\n",
    "\n",
    "df.to_sql('temp_bigquery_stats_cost_monthly', engine, if_exists='replace', index=False)\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execute(\"\"\"\n",
    "        INSERT INTO bigquery_stats_cost_monthly (ym, cost)\n",
    "        SELECT ym, cost\n",
    "        FROM temp_bigquery_stats_cost_monthly\n",
    "        ON CONFLICT (ym) \n",
    "        DO \n",
    "           UPDATE SET cost = excluded.cost\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

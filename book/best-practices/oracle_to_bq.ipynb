{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933ae6b-0083-4eb4-b303-4e468ca019dc",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DT_NODASH = \"20220217\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48a39e-3674-4611-b83f-ae16a223d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -get -f /jars/ojdbc8.jar ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007af8c-d63f-45f5-bb4f-b8d443fe7623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydatafabric.gcp import df_to_bq_table, bq_insert_overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e94827-c5c9-4685-870b-d0ee019db400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_spark(scale=0, queue=None):\n",
    "    import os\n",
    "    import uuid\n",
    "    import tempfile\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pydatafabric.vault_utils import get_secrets\n",
    "    from pyspark import version as spark_version\n",
    "\n",
    "    is_spark_3 = spark_version.__version__ >= \"3.0.0\"\n",
    "\n",
    "    tmp_uuid = str(uuid.uuid4())\n",
    "    app_name = f\"emart-{os.environ.get('USER', 'default')}-{tmp_uuid}\"\n",
    "\n",
    "    key = get_secrets(\"gcp/emart-datafabric/dataflow\")[\"config\"]\n",
    "    key_file_name = tempfile.mkstemp()[1]\n",
    "    with open(key_file_name, \"wb\") as key_file:\n",
    "        key_file.write(key.encode())\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_file.name\n",
    "\n",
    "    if not queue:\n",
    "        if \"JUPYTERHUB_USER\" in os.environ:\n",
    "            queue = \"dmig_eda\"\n",
    "        else:\n",
    "            queue = \"airflow_job\"\n",
    "\n",
    "    bigquery_jars = (\n",
    "        \"hdfs:///jars/spark-bigquery-with-dependencies_2.12-0.21.0.jar,hdfs:///jars/ojdbc8.jar\"\n",
    "        if is_spark_3\n",
    "        else \"hdfs:///jars/spark-bigquery-with-dependencies_2.11-0.17.3.jar,hdfs:///jars/ojdbc8.jar\"\n",
    "    )\n",
    "\n",
    "    arrow_enabled = \"spark.sql.execution.arrow.pyspark.enabled\" if is_spark_3 else \"spark.sql.execution.arrow.enabled\"\n",
    "\n",
    "    arrow_pre_ipc_format = \"0\" if is_spark_3 else \"1\"\n",
    "    os.environ[\"ARROW_PRE_0_15_IPC_FORMAT\"] = arrow_pre_ipc_format\n",
    "\n",
    "    if queue == \"nrt\":\n",
    "        spark = (\n",
    "            SparkSession.builder.config(\"spark.app.name\", app_name)\n",
    "            .config(\"spark.driver.memory\", \"6g\")\n",
    "            .config(\"spark.executor.memory\", \"4g\")\n",
    "            .config(\"spark.driver.maxResultSize\", \"6g\")\n",
    "            .config(\"spark.rpc.message.maxSize\", \"1024\")\n",
    "            .config(\"spark.executor.core\", \"4\")\n",
    "            .config(\"spark.executor.instances\", \"32\")\n",
    "            .config(\"spark.yarn.queue\", queue)\n",
    "            .config(\"spark.ui.enabled\", \"false\")\n",
    "            .config(\"spark.port.maxRetries\", \"128\")\n",
    "            .config(\"spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "            .config(\"spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "            .config(\n",
    "                \"spark.jars\",\n",
    "                bigquery_jars,\n",
    "            )\n",
    "            .config(\"spark.driver.extraClassPath\", \"ojdbc8.jar\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "        )\n",
    "        spark.conf.set(arrow_enabled, \"true\")\n",
    "        return spark\n",
    "\n",
    "    if scale in [1, 2, 3, 4]:\n",
    "        spark = (\n",
    "            SparkSession.builder.config(\"spark.app.name\", app_name)\n",
    "            .config(\"spark.driver.memory\", f\"{scale*8}g\")\n",
    "            .config(\"spark.executor.memory\", f\"{scale*3}g\")\n",
    "            .config(\"spark.executor.instances\", f\"{scale*8}\")\n",
    "            .config(\"spark.driver.maxResultSize\", f\"{scale*4}g\")\n",
    "            .config(\"spark.rpc.message.maxSize\", \"1024\")\n",
    "            .config(\"spark.yarn.queue\", queue)\n",
    "            .config(\"spark.ui.enabled\", \"false\")\n",
    "            .config(\"spark.port.maxRetries\", \"128\")\n",
    "            .config(\"spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "            .config(\"spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "            .config(\n",
    "                \"spark.jars\",\n",
    "                bigquery_jars,\n",
    "            )\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "        )\n",
    "    elif scale in [5, 6, 7, 8]:\n",
    "        spark = (\n",
    "            SparkSession.builder.config(\"spark.app.name\", app_name)\n",
    "            .config(\"spark.driver.memory\", \"8g\")\n",
    "            .config(\"spark.executor.memory\", f\"{2 ** scale}g\")\n",
    "            .config(\"spark.executor.instances\", \"32\")\n",
    "            .config(\"spark.driver.maxResultSize\", \"8g\")\n",
    "            .config(\"spark.rpc.message.maxSize\", \"1024\")\n",
    "            .config(\"spark.yarn.queue\", queue)\n",
    "            .config(\"spark.ui.enabled\", \"false\")\n",
    "            .config(\"spark.port.maxRetries\", \"128\")\n",
    "            .config(\"spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "            .config(\"spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "            .config(\n",
    "                \"spark.jars\",\n",
    "                bigquery_jars,\n",
    "            )\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "        )\n",
    "    else:\n",
    "        if is_spark_3:\n",
    "            spark = (\n",
    "                SparkSession.builder.config(\"spark.app.name\", app_name)\n",
    "                .config(\"spark.driver.memory\", \"8g\")\n",
    "                .config(\"spark.executor.memory\", \"8g\")\n",
    "                .config(\"spark.executor.instances\", \"8\")\n",
    "                .config(\"spark.driver.maxResultSize\", \"6g\")\n",
    "                .config(\"spark.rpc.message.maxSize\", \"1024\")\n",
    "                .config(\"spark.yarn.queue\", queue)\n",
    "                .config(\"spark.ui.enabled\", \"false\")\n",
    "                .config(\"spark.port.maxRetries\", \"128\")\n",
    "                .config(\"spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "                .config(\"spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "                .config(\n",
    "                    \"spark.jars\",\n",
    "                    bigquery_jars,\n",
    "                )\n",
    "                .config(\"spark.driver.extraClassPath\", \"ojdbc8.jar\")\n",
    "                .enableHiveSupport()\n",
    "                .getOrCreate()\n",
    "            )\n",
    "        else:\n",
    "            spark = (\n",
    "                SparkSession.builder.config(\"spark.app.name\", app_name)\n",
    "                .config(\"spark.driver.memory\", \"6g\")\n",
    "                .config(\"spark.executor.memory\", \"8g\")\n",
    "                .config(\"spark.shuffle.service.enabled\", \"true\")\n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "                .config(\"spark.dynamicAllocation.maxExecutors\", \"200\")\n",
    "                .config(\"spark.driver.maxResultSize\", \"6g\")\n",
    "                .config(\"spark.rpc.message.maxSize\", \"1024\")\n",
    "                .config(\"spark.yarn.queue\", queue)\n",
    "                .config(\"spark.ui.enabled\", \"false\")\n",
    "                .config(\"spark.port.maxRetries\", \"128\")\n",
    "                .config(\"spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "                .config(\"spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT\", arrow_pre_ipc_format)\n",
    "                .config(\n",
    "                    \"spark.jars\",\n",
    "                    bigquery_jars,\n",
    "                )\n",
    "                .config(\"spark.driver.extraClassPath\", \"ojdbc8.jar\")\n",
    "                .enableHiveSupport()\n",
    "                .getOrCreate()\n",
    "            )\n",
    "    spark.conf.set(arrow_enabled, \"true\")\n",
    "    return spark\n",
    "\n",
    "spark = get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9b19d-6dd6-4187-96b9-73dae12f7e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_oracle_to_df(spark, dbtable):\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:oracle:thin:@150.204.1.46:1525/WZDB\") \\\n",
    "        .option(\"dbtable\", dbtable) \\\n",
    "        .option(\"user\", \"metatron\") \\\n",
    "        .option(\"password\", \"wisenut2021!\") \\\n",
    "        .load()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86758fd-e84f-4f5f-944c-16cd30d613ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_tables = [\n",
    "    (\"wisenut\", \"wise_neo_tbl_fail_querycnt\", \"fail_dt\"),\n",
    "    (\"wisenut\", \"wise_neo_tbl_pop_querycnt\", \"pop_dt\"),\n",
    "    (\"wisenut\", \"wise_neo_tbl_total_querycnt\", \"total_dt\")\n",
    "]\n",
    "\n",
    "snapshot_tables = [\n",
    "    (\"wisenut\", \"wise_neo_tbl_col_label\"),\n",
    "    (\"wisenut\", \"wise_neo_tbl_dic\"),\n",
    "    (\"wisenut\", \"wise_neo_tbl_except_word\"),\n",
    "    (\"wisenut\", \"wise_neo_tbl_word_code\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc41c0a-016c-49cb-8369-708103f69703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for db, table, dt_col in history_tables:\n",
    "    df = read_oracle_to_df(spark, f\"(SELECT * FROM {db}.{table} WHERE {dt_col} = '{DT_NODASH}') INPUT\")\n",
    "    df_to_bq_table(df, \"temp_1d\", f\"{table}__{DT_NODASH}\")\n",
    "    bq_insert_overwrite(f\"SELECT *, parse_date('%Y%m%d', '{DT_NODASH}') as dt from temp_1d.{table}__{DT_NODASH}\", f\"emart-datafabric.tworld.{table}\", partition=\"dt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c99ac-6e3a-41f8-97b7-d5ade6a04d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for db, table in snapshot_tables:\n",
    "    df = read_oracle_to_df(spark, f\"{db}.{table}\")\n",
    "    df_to_bq_table(df, \"tworld\", f\"{table}\")\n",
    "    print(f\"{db}.{table} done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268f522-4269-44b7-898d-b6cf3c4c6e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

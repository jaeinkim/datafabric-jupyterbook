{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70412046-5aa4-4ef3-a4b0-940c8895d14b",
   "metadata": {},
   "source": [
    "## Oracle 11g character set 한글 인코딩 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da003237-a1e2-42bf-abcd-2f2df5a3de82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-04T23:53:42.700245Z",
     "iopub.status.busy": "2022-10-04T23:53:42.699800Z",
     "iopub.status.idle": "2022-10-04T23:53:42.703308Z",
     "shell.execute_reply": "2022-10-04T23:53:42.702687Z",
     "shell.execute_reply.started": "2022-10-04T23:53:42.700153Z"
    },
    "tags": []
   },
   "source": [
    "### Sample 코드\n",
    "\n",
    "```python\n",
    "from pydatafabric.vault_utils import get_secrets\n",
    "oracle_info = get_secrets(mount_point=\"datafabric\", path=\"oracle/entsal/prd\")\n",
    "\n",
    "from pydatafabric.ye import get_spark\n",
    "spark = get_spark(extra_jars=\"gs://emart-datafabric-resources/jars/ojdbc8.jar,gs://emart-datafabric-resources/jars/orai18n.jar\")\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 2000)\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# AMERICAN_AMERICA.US7ASCII\n",
    "# KOREAN_KOREA.KO16MSWIN949\n",
    "# KOREAN_KOREA.KO16KSC5601\n",
    "# KOREAN_KOREA.AL32UTF8\n",
    "    \n",
    "def read_oracle_to_df(spark, dbtable):\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", oracle_info['jdbc_url']) \\\n",
    "        .option(\"user\", oracle_info['user']) \\\n",
    "        .option(\"password\", oracle_info['password']) \\\n",
    "        .option(\"driver\", \"oracle.jdbc.driver.OracleDriver\") \\\n",
    "        .option(\"oracle.jdbc.timezoneAsRegion\", \"false\") \\\n",
    "        .option(\"dbtable\", dbtable) \\\n",
    "        .load()\n",
    "    return df\n",
    "\n",
    "def convert_col(col):\n",
    "    return \"\".join([c.lower() if c.isupper() else c for c in col])\n",
    "\n",
    "df = read_oracle_to_df(spark, \"(SELECT UTL_RAW.CAST_TO_RAW(CONVERT(COMMENTS, 'AL32UTF8', 'KO16KSC5601')) AS COMMENTS FROM ALL_COL_COMMENTS WHERE TABLE_NAME = 'GTPSS_MALL_SALE') INPUT\")\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# DataFrame의 스키마 이름 가져옴\n",
    "cols = df.schema.names\n",
    "\n",
    "# DataFrame Column 이름을 소문자로 변환\n",
    "df = reduce(lambda _df, col: _df.withColumnRenamed(col, convert_col(col)), [df, *cols])\n",
    "df.printSchema()\n",
    "\n",
    "df.show(n=1, truncate=False, vertical=False)\n",
    "\n",
    "from pydatafabric.gcp import df_to_bq_table, bq_insert_overwrite\n",
    "\n",
    "gcp_table = \"us7ascii_to_utf\"\n",
    "df_to_bq_table(df, \"temp_1d\", f\"{gcp_table}\", project=\"emart-datafabric\", mode=\"overwrite\")    \n",
    "\n",
    "from pydatafabric.gcp import get_bigquery_client\n",
    "\n",
    "bq = get_bigquery_client(project=\"emart-datafabric\") # 프로젝트 꼭 지정\n",
    "r = bq.query(f\"SELECT SAFE_CONVERT_BYTES_TO_STRING(comments) FROM temp_1d.{gcp_table} LIMIT 10\")\n",
    "\n",
    "df = r.result().to_dataframe()\n",
    "\n",
    "spark.stop()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b054080-da39-4c2c-a166-703076156075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

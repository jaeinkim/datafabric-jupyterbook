{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 학습 및 평가\n",
    "\n",
    "## 개요\n",
    "DataFabric의 JupyterHub 환경에서 머신러닝 모델을 만들고 평가할 수 있습니다.\n",
    "DataFabric 분석환경은 Scikit-Learn과 LightGBM 같은 머신러닝 파이썬 패키지를 제공하며 노트북에서 이를 임포트하여 사용할 수 있습니다.\n",
    "이 문서에서는 구글 빅쿼리에 저장된 데이터를 활용하여 추천 모델을 학습하고 평가하는 예제를 설명합니다.\n",
    "\n",
    "\n",
    "## 모델 학습\n",
    "모델 학습 주제 설명"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 확인\n",
    "\n",
    "학습 데이터셋을 만들기 전에 먼저 활용할 데이터를 확인해보는 과정입니다.  \n",
    "사용자 Feature 정보와 라벨링 데이터를 저장하고 있는 테이블을 다음과 같이 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydatafabric.gcp import load_bigquery_ipython_magic\n",
    "\n",
    "load_bigquery_ipython_magic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq \n",
    "SELECT * \n",
    "FROM ...\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq \n",
    "SELECT * \n",
    "FROM ...\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습 데이터 생성\n",
    "구글 빅쿼리에 저장된 데이터를 다음과 같이 쿼리하여 Pandas DataFrame으로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydatafabric.gcp import bq_to_pandas\n",
    "\n",
    "query = f\"\"\"\n",
    "    ...\n",
    "\"\"\"\n",
    "\n",
    "df = bq_to_pandas(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값을 포함하는 데이터를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨 정보를 숫자로 인코딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoding'] = le.fit_transform(df['column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 Feature를 x로 라벨을 y로 하는 데이터셋을 만듭니다.  \n",
    "데이터셋은 학습과 평가로 나누도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "idx_col = ['cust_id', 'dt', 'column', 'dataset_type', 'label', 'label_dt', 'label_encoding']\n",
    "cols = set(df.columns)\n",
    "features = list(cols - set(idx_col))\n",
    "\n",
    "label_col = 'label_encoding'\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df[features], df[label_col], test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능이 좋은 변수만 사용하도록 처리하여 데이터셋을 생성하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "first_k = SelectKBest(score_func=f_classif).fit(train_x, train_y)\n",
    "score = first_k.scores_\n",
    "importance_df = pd.DataFrame(index=train_x.columns, data={'score':first_k.scores_}).sort_values('score', ascending=False)\n",
    "\n",
    "k = 100\n",
    "k_features = list(importance_df.index[:k])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "lgb_trn = lgb.Dataset(train_x[k_features], train_y, feature_name=k_features)\n",
    "lgb_val = lgb.Dataset(valid_x[k_features], valid_y, feature_name=k_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 학습\n",
    "\n",
    "준비된 데이터셋을 이용하여 학습을 합니다. 우선 Bayesian Optimazation을 이용해서 하이퍼 파라미터를 최적화하는 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "LR = 0.05\n",
    "NUM_THREAD = 8\n",
    "\n",
    "def lgb_eval(num_leaves, feature_fraction, lambda_l1, lambda_l2, num_boost_round):\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclassova',\n",
    "        'num_class': num_classes,\n",
    "        'metric': 'multi_logloss',\n",
    "        'is_unbalance': True,\n",
    "        'learning_rate': LR,\n",
    "        'num_threads': NUM_THREAD,\n",
    "        'num_leaves': int(num_leaves),\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'lambda_l1': lambda_l1,\n",
    "        'lambda_l2': lambda_l2\n",
    "    }\n",
    "    \n",
    "    num_boost_round = int(num_boost_round)\n",
    "    \n",
    "    print('num_leaves: ', num_leaves)\n",
    "    print('feature_fraction: ', feature_fraction)\n",
    "    print('lambda_l1: ', lambda_l1)\n",
    "    print('lambda_l2: ', lambda_l2)\n",
    "    print('_num_boost_round: ', num_boost_round)\n",
    "    \n",
    "    clf = lgb.train(params,\n",
    "                    train_set=lgb_trn,\n",
    "                    valid_sets=lgb_val,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=False)\n",
    "    \n",
    "    return clf.best_score['valid_0']['multi_logloss']\n",
    "\n",
    "TARGET_PARAMS = {'num_leaves': (8, 64),\n",
    "                 'feature_fraction': (0.5, 1.0),\n",
    "                 'lambda_l1': (0, 100),\n",
    "                 'lambda_l2': (0, 1000),\n",
    "                 'num_boost_round': (500, 2000)}\n",
    "\n",
    "lgbBO = BayesianOptimization(lgb_eval, TARGET_PARAMS)\n",
    "lgbBO.maximize(init_points=5, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.DataFrame(lgbBO.res)['target'], pd.json_normalize(pd.DataFrame(lgbBO.res)['params'])], axis=1).sort_values(by='target')[::1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화된 파라미터를 사용하여 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclassova',\n",
    "    'num_class': len(le.classes_),\n",
    "    'metric': 'multi_logloss',\n",
    "    'is_unbalance': True,\n",
    "    'num_threads': NUM_THREAD,\n",
    "    'num_leaves': result['num_leaves'].iloc[0].astype('int32'),\n",
    "    'feature_fraction': result['feature_fraction'].iloc[0],\n",
    "    'learning_rate': LR,\n",
    "    'lambda_l1': result['lambda_l1'].iloc[0],\n",
    "    'lambda_l2': result['lambda_l2'].iloc[0]\n",
    "}\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(df[k_features], df[label_col], test_size=0.2, random_state=1234)\n",
    "lgb_trn = lgb.Dataset(train_x, train_y)\n",
    "lgb_val = lgb.Dataset(valid_x, valid_y)\n",
    "\n",
    "# training\n",
    "clf = lgb.train(lgb_params,\n",
    "                train_set=lgb_trn,\n",
    "                valid_sets=[lgb_trn, lgb_val],\n",
    "                num_boost_round=5000,\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 학습된 모델 평가\n",
    "\n",
    "학습한 모델을 평가하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# model evaluation\n",
    "def model_evaluation(model, x_trn, y_trn, top_k):\n",
    "    # cross-table\n",
    "    predict = model.predict(x_trn).argmax(axis=1)\n",
    "    print(pd.crosstab(predict, y_trn))\n",
    "    \n",
    "    # metric by each label\n",
    "    labels, cnt = np.unique(predict, return_counts=True)\n",
    "    metrics_summary = precision_recall_fscore_support(y_true=y_trn, y_pred=predict, labels=labels)\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    \n",
    "    class_report = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index = metrics_sum_index,\n",
    "        columns = labels)\n",
    "    \n",
    "    print(class_report.T)\n",
    "    \n",
    "    # metric by each label\n",
    "    y_tmp = pd.DataFrame(y_trn).reset_index(drop=True)\n",
    "    y_tmp['pred_score'] = list(map(lambda x: x.argsort()[-top_k:][::-1], model.predict(x_trn)))\n",
    "    y_tmp['flag'] = y_tmp.apply(lambda x: int(x['label_encoding'] in x['pred_score']), axis=1)\n",
    "    acc = y_tmp['flag'].sum()/y_tmp['flag'].count()\n",
    "    print(acc)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print(\"[Accuracy for Training Set]\")\n",
    "acc_trn = model_evaluation(clf, train_x, train_y, 3)\n",
    "\n",
    "print(\"[Accuracy for Validation Set]\")\n",
    "acc_val = model_evaluation(clf, valid_x, valid_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 모델은 이후 Prediction 단계에서 사용될 수 있습니다.  \n",
    "다음 단계에서 사용하기 위해 HDFS에 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pydatafabric.ye import get_hdfs_conn\n",
    "\n",
    "model_name = 'example_model'\n",
    "model_version = 'v0'\n",
    "\n",
    "clf.params['label_encoder'] = le\n",
    "clf.params['training_multi_logloss'] = clf.best_score['training']['multi_logloss']\n",
    "clf.params['valid_multi_logloss'] = clf.best_score['valid_1']['multi_logloss']\n",
    "clf.params['acc_trn'] = acc_trn\n",
    "clf.params['acc_val'] = acc_val\n",
    "clf.params['model_name'] = model_name\n",
    "clf.params['model_version'] = model_version\n",
    "\n",
    "# save model file\n",
    "output_path = f'/data/tmp/{model_name}/{model_version}'\n",
    "connection = get_hdfs_conn()\n",
    "with connection.open(os.path.join(output_path), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고로 mlops-sdk를 사용하여 모델의 형상을 관리하실 수 있습니다.\n",
    "모델 관리를 위해서는 mlops에 모델을 등록하셔야 됩니다. MLS에 대한 자세한 내용은 <a href=\"https://rec.shinsegae.ai/swagger/index.html\" target=\"_blank\">mlops-sdk 문서</a>를 참고하시기 바랍니다.\n",
    "아래는 실제 등록된 모델이 저장된 경로를 가져오는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Code Example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}